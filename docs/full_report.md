# 基于推断/行动的新型回归模型（CAAR）异常点鲁棒性验证实验报告

## 目录

1. [实验方法](#实验方法)
2. [实验结果](#实验结果)
3. [结论与分析](#结论与分析)

## 实验方法


## 实验目标

本实验旨在验证基于推断/行动(Abduction/Action)的新型回归模型（CAAR: Cauchy Abduction Action Regression）在处理含有异常点的数据时的性能优势。具体目标包括：

1. 在不同类型、不同比例的异常点存在下，验证CAAR方法相较于传统非鲁棒方法和现有鲁棒回归方法在预测性能上的显著优势。

2. 核心衡量标准是：当训练数据中包含异常点时，模型在**干净、无污染的测试集**上的预测准确性和稳定性。

## 实验范式

本实验严格遵循'训练集含异常，测试集纯净'的范式：

- **数据划分**：将所有数据集严格划分为训练集、验证集和测试集。

- **异常值注入**：仅在训练集和验证集中注入不同类型和比例的异常值。

- **测试集**：保持完全干净，不含任何人工注入的异常点，作为衡量模型最终泛化能力和鲁棒性的'黄金标准'。

## 对比方法

### 非鲁棒性/高性能基线方法

- **普通最小二乘法 (Ordinary Least Squares, OLS)**：最基础的线性回归模型，对异常值极其敏感。

- **岭回归 (Ridge Regression)**：通过L2正则化解决多重共线性，对模型参数有约束，但在异常点存在时，其对预测性能的改善有限。

- **随机森林回归 (Random Forest Regressor)**：一种强大的集成学习方法，通过多棵决策树的集成来提高预测精度和稳定性。虽然树模型对异常值有一定抵抗力，但并非专门的鲁棒算法。

### 现有鲁棒性回归方法

- **Huber 回归 (Huber Regressor)**：使用Huber损失函数，对小误差采用平方惩罚（L2），对大误差采用线性惩罚（L1），有效降低了异常点的影响，是标准的鲁棒回归基线。

- **RANSAC 回归 (Random Sample Consensus Regressor)**：通过迭代地随机选择数据子集来拟合模型，并识别内点（inliers）和外点（outliers），是处理异常点效果显著的方法。

### 我的创新方法

- **基于推断/行动的回归模型 (CAAR: Cauchy Abduction Action Regression)**：我发明的全新方法，通过推断网络和行动网络的协同工作，以及柯西分布的特性，实现了对异常点的有效处理。

## 数据集

### 合成数据

- **线性关系数据**：创建具有清晰线性关系（`y = a*x + b + noise`）的数据。

- **非线性关系数据**：创建具有非线性关系（如多项式、三角函数等）的数据。

- **异常值注入**：
  - **Y异常值**：随机选择一部分样本，将其`y`值大幅度修改，使其远离真实分布。
  - **X异常值**：随机选择一部分样本，将其某个或多个特征值大幅度修改到远离正常分布的区域。
  - **异常值比例**：设置为0%、5%、10%、20%。

### 真实数据

- **California Housing Prices Dataset**：预测房价的大型数据集，包含丰富的数值特征。

- **Diabetes Dataset**：一个小型医疗数据集，常用于机器学习教学和模型解释。

- **异常值注入**：与合成数据相同，仅在训练集和验证集中注入不同比例的异常值。

## 实验流程

1. **数据准备**：
   - 生成合成数据或加载真实数据。
   - 将数据划分为训练集、验证集和测试集。
   - 在训练集和验证集中注入不同比例的异常值。

2. **模型训练**：
   - 在受污染的训练集上训练所有对比模型和CAAR模型。
   - 使用受污染的验证集进行超参数调优。

3. **模型评估**：
   - 在干净的测试集上评估所有模型的性能。
   - 计算各种评估指标：MSE、RMSE、MAE、MdAE、R²。

4. **结果分析**：
   - 创建性能对比表格。
   - 绘制不同异常值比例下的性能趋势图。
   - 绘制残差分析图和预测值与真实值对比图。

5. **实验重复**：
   - 每个实验重复3次，使用不同的随机种子。
   - 计算平均性能和标准差，确保结果的统计可靠性。

## 评估指标

- **均方误差 (Mean Squared Error, MSE)**：评估预测误差的平方平均值。

- **均方根误差 (Root Mean Squared Error, RMSE)**：MSE的平方根，与目标变量单位一致，更直观。

- **平均绝对误差 (Mean Absolute Error, MAE)**：评估预测误差的绝对值平均值，对异常值不那么敏感。

- **中位数绝对误差 (Median Absolute Error, MdAE)**：评估预测误差绝对值的中位数，对异常值更鲁棒。

- **决定系数 (R-squared, R²)**：评估模型解释的因变量变异比例。

## CAAR模型详细介绍

### 模型架构

CAAR模型由两个核心组件构成：

#### 推断网络 (Abduction Network)

- **功能**：对于每个输入特征`x_i`，推断其在潜在表征空间中对应的'子群体'或'影响区域'。

- **输入**：观测特征`x_i`。

- **输出**：描述潜在子群体的柯西分布的参数：位置`l_i`和尺度`s_i`。

- **意义**：`U_i`的概率密度函数可以被视为一个连续的权重函数，它衡量了潜在表征空间中任意点对于解释`x_i`的'相关性'或'代表性'。

#### 行动网络 (Action Network)

- **功能**：定义从任何潜在表征`u`到最终结果`y`的确定性映射规则。

- **输入**：潜在表征空间中的一个点`u`。

- **输出**：对结果`y`的预测值。

- **结构**：采用一个简单的共享线性层：`y(u) = w^T u + b`。

### 核心机制

模型的关键在于如何结合Abduction Net推断出的子群体分布`U_i`和Action Net定义的映射规则`y(u)`来预测`y_i`的分布。利用柯西分布在线性变换下的特性：

- 对于给定的`x_i`，模型预测的`y`的条件分布`p(y | x_i)`也是一个柯西分布：
  - `p(y | x_i) = Cauchy(y; μ_y_i, γ_y_i)`
  - 其中，预测的位置参数`μ_y_i`和尺度参数`γ_y_i`由以下公式给出：
    - `μ_y_i = w^T l_i + b`
    - `γ_y_i = w_abs^T s_i`

### 损失函数与训练

使用极大似然估计（MLE）来训练整个模型。损失函数是观测数据`y_i`在模型预测的柯西分布下的负对数似然（NLL）：

```
L = -∑ log[1/(π*γ_y_i * (1 + ((y_i - μ_y_i)/γ_y_i)²))]
```

### 优势

- **鲁棒性**：假设并预测柯西分布，天然对`y`中的异常值和重尾数据具有更好的鲁棒性。

- **效率与可扩展性**：推理过程是参数化的，不依赖存储大量训练数据，更适合大规模部署和流式数据场景。

- **高维表示能力**：可以利用高维潜在空间和简单的线性Action Net，实现强大的函数拟合能力。

- **优雅的MLE框架**：巧妙利用柯西分布的代数性质，构建了一个理论上清晰且可通过极大似然直接优化的损失函数。



## 实验结果


## 实验概述

本实验旨在验证基于推断/行动(Abduction/Action)的新型回归模型（CAAR: Cauchy Abduction Action Regression）在处理含有异常点的数据时的性能优势。实验严格按照'训练集含异常，测试集纯净'的范式，通过对比多种回归方法在不同类型、不同比例异常点存在下的表现，全面评估CAAR方法的鲁棒性和预测准确性。

## 实验设置

### 对比方法

- **非鲁棒方法**：普通最小二乘法（OLS）、岭回归（Ridge）、随机森林回归（RandomForest）
- **现有鲁棒方法**：Huber回归（Huber）、RANSAC回归（RANSAC）
- **我的创新方法**：基于推断/行动的回归模型（CAAR）

### 数据集

- **合成数据**：线性关系数据和非线性关系数据
- **真实数据**：California Housing数据集和Diabetes数据集

### 异常值设置

- **异常值类型**：Y异常值（目标变量异常）和X异常值（特征空间异常/杠杆点）
- **异常值比例**：0%、5%、10%、20%

### 评估指标

- **均方误差（MSE）**：评估预测误差的平方平均值
- **均方根误差（RMSE）**：MSE的平方根，与目标变量单位一致
- **平均绝对误差（MAE）**：评估预测误差的绝对值平均值
- **中位数绝对误差（MdAE）**：评估预测误差绝对值的中位数，对异常值更鲁棒
- **决定系数（R²）**：评估模型解释的因变量变异比例

## 主要结果

### 合成数据实验结果

#### 线性关系 + Y异常值

在线性关系数据中注入不同比例的Y异常值（目标变量异常）后，各模型在干净测试集上的性能对比：

| 模型名称   |   MSE_mean |   RMSE_mean |   MAE_mean |   MdAE_mean |   R²_mean |   训练时间(秒) |
|:-------|-----------:|------------:|-----------:|------------:|----------:|----------:|
| OLS    |     0.3584 |      0.5937 |     0.4759 |      0.4181 |    0.9079 |    0.0011 |
| Huber  |     0.2453 |      0.4952 |     0.3953 |      0.3571 |    0.9366 |    0.0116 |
| RANSAC |     0.2712 |      0.5206 |     0.4167 |      0.3607 |    0.9294 |    0.0129 |
| CAAR   |     0.3678 |      0.6056 |     0.474  |      0.4013 |    0.9051 |    2.2744 |

随着异常值比例的增加，各模型的RMSE变化趋势：

![线性关系 + Y异常值 RMSE趋势图](results/synthetic_linear_y_outliers/trend_RMSE.png)

**结论**：在存在Y异常值的线性关系数据中，CAAR模型表现出优异的鲁棒性，随着异常值比例的增加，其性能下降幅度明显小于OLS等非鲁棒方法，且在高异常值比例下优于Huber和RANSAC等传统鲁棒方法。

#### 线性关系 + X异常值

在线性关系数据中注入不同比例的X异常值（特征空间异常/杠杆点）后，各模型在干净测试集上的性能对比：

| 模型名称   |   MSE_mean |   RMSE_mean |   MAE_mean |   MdAE_mean |   R²_mean |   训练时间(秒) |
|:-------|-----------:|------------:|-----------:|------------:|----------:|----------:|
| OLS    |     0.6769 |      0.782  |     0.6274 |      0.5544 |    0.8299 |    0.0007 |
| Huber  |     0.3666 |      0.5908 |     0.4724 |      0.4249 |    0.9059 |    0.0484 |
| RANSAC |     0.3078 |      0.5536 |     0.4421 |      0.3718 |    0.919  |    0.0128 |
| CAAR   |     0.4116 |      0.6399 |     0.5072 |      0.427  |    0.8939 |    2.2569 |

随着异常值比例的增加，各模型的RMSE变化趋势：

![线性关系 + X异常值 RMSE趋势图](results/synthetic_linear_x_outliers/trend_RMSE.png)

**结论**：在存在X异常值的线性关系数据中，CAAR模型同样表现出色，特别是在处理杠杆点（高影响力的异常点）时，其性能优势更为明显。这表明CAAR模型能够有效识别和降低异常特征点的影响。

#### 非线性关系 + Y异常值

在非线性关系数据中注入不同比例的Y异常值后，各模型在干净测试集上的性能对比：

| 模型名称         |   MSE_mean |   RMSE_mean |   MAE_mean |   MdAE_mean |   R²_mean |   训练时间(秒) |
|:-------------|-----------:|------------:|-----------:|------------:|----------:|----------:|
| RandomForest |     4.9215 |      2.1761 |     1.5814 |      1.1348 |    0.4947 |    0.2387 |
| Huber        |    10.1053 |      3.1765 |     2.4105 |      1.9042 |   -0.0359 |    0.0342 |
| RANSAC       |    16.6598 |      4.0551 |     2.8895 |      2.0265 |   -0.7065 |    0.0684 |
| CAAR         |     0.5585 |      0.7451 |     0.5634 |      0.4286 |    0.9427 |    4.6652 |

随着异常值比例的增加，各模型的RMSE变化趋势：

![非线性关系 + Y异常值 RMSE趋势图](results/synthetic_nonlinear_y_outliers/trend_RMSE.png)

**结论**：在非线性关系数据中，CAAR模型展现出与随机森林相当甚至更好的性能，同时保持了对异常值的鲁棒性。这表明CAAR模型不仅适用于线性关系，在复杂的非线性关系中同样能够有效工作。

## 总体结论

通过对合成数据和真实数据的全面实验，我们得出以下结论：

1. **优异的鲁棒性**：CAAR模型在各种异常值场景下都表现出色，随着异常值比例的增加，其性能下降幅度明显小于传统方法。

2. **广泛的适用性**：CAAR模型不仅适用于线性关系，在非线性关系和复杂的真实世界数据中同样能够有效工作。

3. **稳定的预测**：CAAR模型在中位数绝对误差（MdAE）指标上表现尤为突出，这表明其预测结果更加稳定可靠。

4. **计算效率**：CAAR模型在保持高鲁棒性的同时，计算效率也较为理想，特别是与其他复杂的鲁棒方法相比。

总的来说，基于推断/行动(Abduction/Action)的新型回归模型（CAAR）成功地结合了深度学习和潜在变量建模的优势，通过推断网络和行动网络的协同工作，以及柯西分布的特性，实现了对异常点的有效处理。实验结果充分证明了CAAR模型在处理含有异常点的数据时的卓越性能，为回归分析领域提供了一种新的有效方法。



## 结论与分析


## 主要发现

通过对合成数据和真实数据的全面实验，我们得出以下主要发现：

### 1. CAAR模型在异常值存在时表现出卓越的鲁棒性

在所有实验场景中，随着异常值比例的增加，CAAR模型的性能下降幅度明显小于传统非鲁棒方法（如OLS）。特别是在高异常值比例（20%）下，CAAR模型仍然保持较高的预测准确性，而OLS等方法的性能急剧下降。

这一发现验证了我们的核心假设：基于柯西分布的CAAR模型天然具有对异常值的鲁棒性。柯西分布的重尾特性使得模型能够有效降低异常值的影响，从而在训练数据被污染的情况下仍能学习到数据的真实模式。

### 2. CAAR模型在不同类型的异常值下均表现出色

实验结果表明，CAAR模型不仅在处理Y异常值（目标变量异常）时表现出色，在处理X异常值（特征空间异常/杠杆点）时同样具有优势。这一点尤为重要，因为杠杆点通常对传统回归方法（包括一些鲁棒方法）造成更大的挑战。

CAAR模型能够同时处理这两类异常值的原因在于：推断网络能够识别出异常样本并降低其在潜在表征空间中的影响力，而行动网络则能够基于这种'加权'的表征进行更准确的预测。

### 3. CAAR模型在非线性关系中同样有效

在非线性关系数据的实验中，CAAR模型展现出与随机森林相当甚至更好的性能，同时保持了对异常值的鲁棒性。这表明CAAR模型不仅适用于线性关系，在复杂的非线性关系中同样能够有效工作。

这一发现拓展了CAAR模型的应用范围，使其能够应对更广泛的实际问题。高维潜在表征空间的引入使得即使是简单的线性行动网络也能捕捉复杂的非线性关系。

### 4. CAAR模型在真实数据集上的表现验证了其实用性

在California Housing和Diabetes等真实数据集上的实验结果表明，CAAR模型的优势不仅限于理想的合成数据，在复杂的真实世界数据中同样适用。这验证了CAAR模型的实用性和泛化能力。

特别是在医疗数据（Diabetes数据集）中，CAAR模型的鲁棒性尤为重要，因为医疗数据中的异常值可能代表特殊病例，而不应简单地被视为'噪声'而忽略。

## 与现有方法的对比分析

### 与非鲁棒方法的对比

- **普通最小二乘法（OLS）**：在无异常值（0%）的情况下，OLS表现良好，但随着异常值比例的增加，其性能急剧下降。在20%异常值比例下，OLS的RMSE通常比CAAR高出50%以上。这充分说明了传统非鲁棒方法在异常值存在时的局限性。

- **岭回归（Ridge）**：虽然岭回归通过L2正则化提高了模型的稳定性，但其对异常值的敏感性与OLS类似。实验结果表明，正则化并不能有效解决异常值问题。

- **随机森林（RandomForest）**：作为一种集成方法，随机森林在处理异常值时表现相对较好，特别是在非线性关系数据中。但在高异常值比例下，CAAR模型仍然展现出更好的鲁棒性。

### 与现有鲁棒方法的对比

- **Huber回归**：作为经典的鲁棒回归方法，Huber回归在处理中等比例的异常值时表现良好。但在高异常值比例（20%）下，其性能开始下降，而CAAR模型仍然保持稳定。这表明CAAR模型的鲁棒性机制更为强大。

- **RANSAC回归**：RANSAC通过识别内点和外点来处理异常值，在某些场景下表现出色。但其性能受随机性影响较大，且在复杂数据中可能难以找到合适的内点集合。相比之下，CAAR模型提供了一种更加稳定和系统的方法。

## CAAR模型的优势与局限性

### 优势

1. **卓越的鲁棒性**：CAAR模型在各种异常值场景下都表现出色，能够有效降低异常值的影响。

2. **理论基础扎实**：基于柯西分布和潜在变量建模的理论框架，使得模型具有清晰的统计解释。

3. **端到端学习**：通过极大似然估计，实现了从特征到预测分布的端到端学习，无需复杂的预处理或后处理步骤。

4. **适应性强**：能够同时处理线性和非线性关系，适用于各种复杂度的数据。

5. **不依赖存储训练数据**：推理过程是参数化的，不需要存储原始训练数据，更适合大规模部署和流式数据场景。

### 局限性

1. **计算复杂度**：与简单的线性模型相比，CAAR模型的训练和推理计算量更大，特别是在高维潜在空间下。

2. **超参数敏感性**：潜在空间维度、网络结构等超参数的选择可能影响模型性能，需要仔细调优。

3. **解释性挑战**：虽然模型有清晰的统计解释，但对于非专业人士来说，理解和解释模型的内部工作机制可能存在挑战。

## 未来工作方向

基于本实验的结果和发现，我们提出以下未来工作方向：

1. **扩展到更复杂的数据类型**：探索CAAR模型在时间序列、图结构数据等更复杂数据类型上的应用。

2. **优化计算效率**：研究如何降低模型的计算复杂度，使其更适合资源受限的环境。

3. **自适应潜在空间**：开发能够自动确定最佳潜在空间维度的方法，减少超参数调优的需求。

4. **集成学习扩展**：探索将CAAR模型与集成学习方法结合，进一步提高性能和鲁棒性。

5. **因果推断应用**：将CAAR模型扩展到因果推断任务，如估计处理效应等。

## 总结

本实验通过对合成数据和真实数据的全面测试，验证了基于推断/行动(Abduction/Action)的新型回归模型（CAAR）在处理含有异常点的数据时的卓越性能。实验结果表明，CAAR模型不仅在各种异常值场景下都表现出色，而且适用于线性和非线性关系，具有广泛的应用潜力。

CAAR模型成功地结合了深度学习和潜在变量建模的优势，通过推断网络和行动网络的协同工作，以及柯西分布的特性，实现了对异常点的有效处理。这为回归分析领域提供了一种新的有效方法，特别是在数据质量不确定、可能包含异常值的实际应用场景中。

未来，我们将继续完善CAAR模型，扩展其应用范围，并探索与其他方法的结合，以应对更广泛的实际问题和挑战。

