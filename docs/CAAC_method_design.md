# CAAC (Cauchy Inference Action Classification) 方法设计文档

## 1. 背景与动机

在成功构建了用于回归任务的 CAAR (Cauchy Additive Autoregressive Regression) 方法后，我们现在着手设计一个统一的因果大模型架构，能够同时处理分类和回归任务。CAAC 旨在成为这个架构中处理分类任务的核心组件。

我们的核心目标是：
- 利用柯西分布的重尾特性来建模潜在变量，提高模型对异常值的鲁棒性
- 构建一个具有封闭解析NLL（负对数似然）的模型，便于梯度优化
- 避免采样过程，保证训练和推理的确定性
- 保持模型的因果解释性
- **关键约束**：输入数据 $x$ 仅应影响因果表征的生成，而因果表征到分类结果的映射机制应该是固定的、不依赖于特定输入的

## 2. 方案演进过程

### 2.1 初始多层柯西架构的探索与问题

**初始设想**：通过多层嵌套的柯西分布和 ALR (Additive Log-Ratio) 变换来构建分类模型：

$$x \rightarrow h(x) \rightarrow P(C|x) \sim \text{MCauchy}(\mu_C(h), \gamma_C(h))$$

其中包含高维因果表征 $C$、噪声 $\varepsilon$、线性变换和最终的ALR变换到分类概率。

**数学障碍**：为了获得封闭的NLL，需要计算：

$$P(Y=j|x) = \mathbb{E}_{C|x} \left[ \mathbb{E}_{\varepsilon|x} \left[ \mathbb{E}_{Z_1...Z_{K-1} | V(C,\varepsilon)} \left[ \text{ALR}_j(Z_1...Z_{K-1}) \right] \right] \right]$$

这种多层期望计算涉及没有初等函数封闭解的积分（如柯西分布与sigmoid函数的积分），无法满足"封闭解析NLL"的核心要求。

**结论**：初始的多层柯西架构在数学上不可行。

### 2.2 基础动态阈值方案：突破封闭解难题

**核心思想**：将问题简化为基于柯西分布的一维得分和分段分类：

$$x \rightarrow h(x) \rightarrow \begin{cases}
\mu_s(h), \gamma_s(h) & \text{(柯西得分参数)} \\
\theta_1(h), ..., \theta_{K-1}(h) & \text{(动态阈值)}
\end{cases}$$

**数学优势**：利用柯西CDF的封闭形式：
$$F_S(s; \mu, \gamma) = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{s - \mu}{\gamma}\right)$$

分类概率变为：
$$P(Y=k|x) = F_S(\theta_k(h)) - F_S(\theta_{k-1}(h))$$

**成就**：成功获得封闭解析NLL，但存在两个关键问题：
1. 缺乏显式的高维因果表征层
2. **决策阈值依赖于输入数据**，违背机制不变性原则

### 2.3 进阶动态阈值方案：引入显式因果表征

**设计改进**：引入显式的 $d_c$ 维独立柯西因果表征层：

$$x \rightarrow h(x) \rightarrow (\vec{\mu}_C(h), \vec{\gamma}_C(h)) \rightarrow \begin{cases}
\mu_s(h), \gamma_s(h) & \text{(通过线性组合)} \\
\theta_k(h) & \text{(通过小型神经网络)}
\end{cases}$$

具体地：
- $\mu_s(h) = \vec{\mu}_C(h)^T \vec{W}_\mu + b_\mu$
- $\gamma_s(h) = \sum_{i=1}^{d_c} |W_{\gamma,i}| \gamma_{C_i}(h) + \gamma_{\epsilon_0}$
- $\theta_k(h)$ 由 $\vec{\mu}_C(h)$ 通过MLP生成

**优势**：
- 显式高维因果表征层，更符合统一因果模型的目标
- 结构化的参数生成逻辑
- 保持封闭解析NLL

**核心问题仍未解决**：分类阈值 $\theta_k(h)$ 仍然依赖于输入数据，这与"因果表征一旦形成，其到结果的映射机制应更通用"的直觉相冲突。

## 3. CAAC-SPSFT：最终解决方案

### 3.1 核心设计理念

CAAC-SPSFT (Stochastic Pathway Selection with Fixed Thresholds) 方案彻底解决了机制不变性问题：

- **数据影响局限化**：输入 $x$ 仅影响因果表征 $C$ 的参数生成
- **机制固定化**：从因果表征到分类结果的所有决策机制都是全局固定的
- **多路径混合**：通过 $K$ 个并行的"解读路径"增强模型表达能力

### 3.2 完整数学架构

#### 3.2.1 输入到因果表征
$$x \rightarrow h(x) \rightarrow (\vec{\mu}_C(h), \vec{\gamma}_C(h))$$

其中 $\vec{\mu}_C(h) = (\mu_{C_1}(h), ..., \mu_{C_{d_c}}(h))$ 和 $\vec{\gamma}_C(h) = (\gamma_{C_1}(h), ..., \gamma_{C_{d_c}}(h))$ 定义了 $d_c$ 维独立柯西因果表征的分布参数。

#### 3.2.2 因果表征到多路径得分

对于每条路径 $j \in \{1, ..., K\}$，通过线性变换生成路径特定的柯西得分参数：

**位置参数**：
$$\mu_{S_j}(h) = (\vec{W}_{\mu}^{(j)})^T \vec{\mu}_C(h) + b_{\mu}^{(j)}$$

**尺度参数**：
$$\gamma_{S_j}(h) = \sum_{i=1}^{d_c} |W_{\gamma,i}^{(j)}| \gamma_{C_i}(h) + \gamma_{\epsilon_0}^{(j)}$$

其中 $\gamma_{\epsilon_0}^{(j)} = \exp(\text{raw\_}\gamma_{\epsilon_0}^{(j)})$ 确保正性。

#### 3.2.3 固定决策机制

**路径选择概率**（全局固定）：
$$\pi_j = \frac{\exp(l_j)}{\sum_{p=1}^K \exp(l_p)}$$

**分类阈值**（全局固定）：
$$\vec{\theta}^* = (\theta_1^* < \theta_2^* < ... < \theta_{K-1}^*)$$

#### 3.2.4 最终分类概率

每条路径 $j$ 给出的类别 $k$ 概率：
$$P(Y=k|M=j, x) = F_{S_j}(\theta_k^*) - F_{S_j}(\theta_{k-1}^*)$$

其中 $F_{S_j}$ 是柯西CDF：
$$F_{S_j}(s) = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{s - \mu_{S_j}(h)}{\gamma_{S_j}(h)}\right)$$

最终混合概率：
$$P(Y=k|x) = \sum_{j=1}^K \pi_j \cdot P(Y=k|M=j, x)$$

### 3.3 方案对比总结

| 方案 | 因果表征 | 决策机制 | 封闭NLL | 机制不变性 |
|------|----------|----------|---------|------------|
| 初始多层柯西 | ✓ 高维 | 复杂嵌套 | ✗ | N/A |
| 基础动态阈值 | ✗ 缺失 | 动态阈值 | ✓ | ✗ |
| 进阶动态阈值 | ✓ 高维 | 动态阈值 | ✓ | ✗ |
| **CAAC-SPSFT** | ✓ 高维 | **固定机制** | ✓ | ✓ |

## 4. CAAC-SPSFT 参数设计深入讨论

### 4.1 因果表征维度 $d_c$ 的选择

**设计考量**：
- **表达能力 vs 计算复杂度**：$d_c$ 决定了因果表征的丰富程度，但也直接影响后续每条路径的参数量
- **与任务复杂度的匹配**：对于 $K$ 类分类任务，$d_c$ 应该有足够的维度来捕获类别间的区别性信息
- **与编码器输出维度的关系**：$h(x)$ 的维度应该能够有效支撑 $2d_c$ 个输出（$\vec{\mu}_C$ 和 $\vec{\gamma}_C$）

**经验准则**：
- 起始点：$d_c = \lceil \log_2(K) \rceil \times 4$ 到 $d_c = K$
- 上界：避免 $d_c > K \times 10$，防止过度参数化
- 下界：确保 $d_c \geq \max(3, \lceil \log_2(K) \rceil)$，保证基本表达能力

### 4.2 路径数量 $K$ 的设计

**主要选择**：
1. **$K =$ 类别数量**：最直观的选择，每个路径对应一个类别的"视角"
2. **$K > $ 类别数量**：增加表达能力，但显著增加参数量
3. **$K < $ 类别数量**：减少复杂度，但可能损失表达能力

**权衡分析**：
- **参数量影响**：总参数量约为 $K \times (2d_c + 1)$（线性变换参数）
- **训练稳定性**：$K$ 过大可能导致路径间竞争，训练不稳定
- **可解释性**：$K =$ 类别数量时，每条路径可能自然对应某种类别特异的"解读方式"

### 4.3 线性变换参数的初始化策略

#### 4.3.1 位置参数权重 $\vec{W}_{\mu}^{(j)}$ 和偏置 $b_{\mu}^{(j)}$

**初始化原则**：
- **避免路径塌陷**：确保不同路径 $j$ 的 $\vec{W}_{\mu}^{(j)}$ 有足够的差异性
- **平衡性**：避免某些路径在初始化时就占据主导地位

**具体策略**：
1. **正交初始化**：当 $K \leq d_c$ 时，可以使用正交矩阵的行作为 $\vec{W}_{\mu}^{(j)}$
2. **随机扰动**：$\vec{W}_{\mu}^{(j)} \sim \mathcal{N}(0, \sigma^2/d_c)$，其中 $\sigma \approx 1.0$
3. **偏置设置**：$b_{\mu}^{(j)} = (j-1) \times \Delta$，其中 $\Delta$ 是一个小的间隔（如 $0.5$），确保初始时不同路径有不同的"基线"

#### 4.3.2 尺度参数权重 $\vec{W}_{\gamma}^{(j)}$ 和 $\gamma_{\epsilon_0}^{(j)}$

**设计目标**：
- **尺度参数的物理意义**：$\gamma_{S_j}(h)$ 表示路径 $j$ 下得分的"不确定性"
- **避免过大或过小**：防止数值不稳定或信息丢失

**初始化策略**：
1. **权重初始化**：$W_{\gamma,i}^{(j)} \sim \text{Uniform}(-0.1, 0.1)$，初始时让因果表征的贡献较小
2. **基础尺度**：$\text{raw\_}\gamma_{\epsilon_0}^{(j)} \sim \mathcal{N}(\log(1.0), 0.1^2)$，对应 $\gamma_{\epsilon_0}^{(j)} \approx 1.0$
3. **路径差异化**：不同路径 $j$ 可以有轻微不同的初始基础尺度

### 4.4 固定阈值 $\vec{\theta}^*$ 的设计

#### 4.4.1 阈值数量与位置

**基本约束**：$\theta_1^* < \theta_2^* < ... < \theta_{K-1}^*$

**初始化策略**：
1. **均匀分布**：$\theta_k^* = \Phi^{-1}(\frac{k}{K})$，其中 $\Phi^{-1}$ 是标准正态分布的逆CDF
2. **基于先验**：如果有类别分布的先验知识，可以设置为累积概率的分位点
3. **对称分布**：$\theta_k^* = (k - \frac{K}{2}) \times \Delta$，其中 $\Delta \approx 1.0$

#### 4.4.2 阈值的学习与约束

**约束实现**：
- 参数化为第一个阈值 $\theta_1^*$ 和正的差值 $\{\delta_2^*, ..., \delta_{K-1}^*\}$
- $\delta_k^* = \exp(\text{raw\_}\delta_k^*)$ 或 $\delta_k^* = \text{softplus}(\text{raw\_}\delta_k^*)$

**学习率调整**：
- 阈值参数通常需要比网络权重更小的学习率
- 建议使用 $\text{lr}_{\theta} = 0.1 \times \text{lr}_{\text{main}}$

### 4.5 路径选择概率 $\vec{\pi}$ 的设计

#### 4.5.1 初始化策略

**平衡初始化**：
- $l_j = 0$ for all $j$，对应 $\pi_j = \frac{1}{K}$（均匀分布）
- 或者基于类别先验设置不均匀的初始分布

**多样性鼓励**：
- 在训练早期可以添加熵正则化：$-\lambda \sum_j \pi_j \log \pi_j$
- 防止单一路径主导的问题

#### 4.5.2 路径专门化机制

**自然专门化期望**：
- 理想情况下，不同路径 $j$ 应该自发地专门化处理某些类型的输入
- 路径选择概率 $\pi_j$ 反映了该路径的"重要性"或"适用范围"

**监控指标**：
- **路径利用率**：$\text{effective\_paths} = \exp(-\sum_j \pi_j \log \pi_j)$
- **路径特异性**：分析每条路径在不同类别上的表现差异

### 4.6 超参数调优的优先级

**第一优先级**（对性能影响最大）：
1. 因果表征维度 $d_c$
2. 路径数量 $K$
3. 基础尺度参数 $\gamma_{\epsilon_0}^{(j)}$ 的初始值

**第二优先级**（对训练稳定性影响大）：
1. 阈值的初始位置和学习率
2. 位置参数权重的初始化方式
3. 路径选择概率的正则化强度

**第三优先级**（精细调优）：
1. 尺度参数权重的初始化
2. 偏置项的设置
3. 不同参数组的学习率比例

### 4.7 潜在的设计变体

#### 4.7.1 自适应路径数量

**动态路径修剪**：
- 训练过程中监控 $\pi_j$，自动移除贡献很小的路径
- 实现方式：当 $\pi_j < \epsilon$ 持续多个epoch时，固定该路径的参数

#### 4.7.2 层次化路径结构

**分层路径选择**：
- 首先选择路径组，然后在组内选择具体路径
- 可能有助于处理具有层次结构的分类任务

#### 4.7.3 条件化阈值

**部分条件化**：虽然完全固定的阈值是我们的目标，但可以考虑基于全局统计量（而非特定输入）的微调：
$$\theta_k^* = \theta_{k,\text{base}}^* + \alpha \cdot \text{global\_shift}$$

其中 $\text{global\_shift}$ 是基于整个数据集统计的全局调整。

## 5. 总结与展望

CAAC-SPSFT 方案通过渐进式的设计改进，最终实现了：
1. **保持封闭解析NLL**：从基础动态阈值方案继承的核心优势
2. **显式因果表征**：从进阶动态阈值方案继承的结构完整性
3. **机制不变性**：通过固定决策机制彻底解决的核心问题

这个演进过程展示了在复杂约束下进行模型设计的思考路径：从数学可行性出发，逐步完善模型结构，最终在多个设计目标间找到最优平衡。

**下一步工作重点**：
1. **实验验证**：在真实分类任务上验证不同参数设计选择的有效性
2. **理论分析**：进一步分析混合柯西分布的表达能力边界
3. **与CAAR统一**：探索将CAAC-SPSFT与回归任务的CAAR方法统一到同一框架中 