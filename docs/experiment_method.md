# 异常点鲁棒性验证实验方法

## 实验目标

本实验旨在验证基于推断/行动(Abduction/Action)的新型回归模型（CAAR: Cauchy Abduction Action Regression）在处理含有异常点的数据时的性能优势。具体目标包括：

1. 在不同类型、不同比例的异常点存在下，验证CAAR方法相较于传统非鲁棒方法和现有鲁棒回归方法在预测性能上的显著优势。

2. 核心衡量标准是：当训练数据中包含异常点时，模型在**干净、无污染的测试集**上的预测准确性和稳定性。

## 实验范式

本实验严格遵循'训练集含异常，测试集纯净'的范式：

- **数据划分**：将所有数据集严格划分为训练集、验证集和测试集。

- **异常值注入**：仅在训练集和验证集中注入不同类型和比例的异常值。

- **测试集**：保持完全干净，不含任何人工注入的异常点，作为衡量模型最终泛化能力和鲁棒性的'黄金标准'。

## 对比方法

### 非鲁棒性/高性能基线方法

- **普通最小二乘法 (Ordinary Least Squares, OLS)**：最基础的线性回归模型，对异常值极其敏感。

- **随机森林回归 (Random Forest Regressor)**：一种强大的集成学习方法，通过多棵决策树的集成来提高预测精度和稳定性。虽然树模型对异常值有一定抵抗力，但并非专门的鲁棒算法。

- **XGBoost 回归 (XGBoost Regressor)**：高性能梯度提升集成方法，当前机器学习竞赛中最流行的算法之一，性能卓越。

### 基于神经网络的对比及鲁棒回归方法

- **MLP (多层感知机回归 - MSE损失)**：标准神经网络模型，使用均方误差(MSE)损失，作为其他基于MLP方法的基础对比。

- **MLP_Huber (多层感知机回归 - Huber损失)**：与MLP结构相似，但使用Huber损失函数（实验中设置delta=1.35），旨在平衡MSE和MAE的特性以抵抗异常值。

- **MLP_Pinball_Median (多层感知机回归 - Pinball损失实现中位数回归)**：与MLP结构相似，但使用Pinball损失函数（quantile=0.5）来拟合条件中位数，旨在通过优化中位数目标提升鲁棒性。

- **MLP_Cauchy (多层感知机回归 - Cauchy损失)**：采用标准的MLP结构，直接使用柯西分布的负对数似然 $\log(1 + (y - \hat{y})^2)$ 作为损失函数。此模型不包含推断/行动框架，主要用于与`CAAR`对比，以评估推断/行动框架在柯西损失之外的额外贡献。

### 我们的创新方法（基于推断/行动框架）

- **CAAR (柯西推断行动回归)**：通过推断网络为每个样本推断潜在子群体的柯西分布，并利用行动网络进行回归。柯西分布的重尾特性使其对异常值具有天然的鲁棒性。

- **GAAR (高斯推断行动回归)**：与CAAR结构相似，但推断网络基于高斯分布假设，用作对比分析分布假设对鲁棒性的影响。

## 数据集

### 合成数据

- **线性关系数据**：创建具有清晰线性关系（$y = ax + b + \text{noise}$）的数据。

- **非线性关系数据 ('interactive_heteroscedastic')**：创建具有非线性关系的复杂数据，包含特征间的交互项以及异方差性（误差方差随X变化），更接近真实世界数据的复杂性。具体函数形式为：$y = 10 \sin(X_{:,0} \cdot X_{:,1}) + 20(X_{:,2} - 0.5)^2 + 10X_{:,3} + 5X_{:,4} + \text{error}$。

- **异常值注入**：
  - **Y异常值**：随机选择一部分样本，将其 $y$ 值大幅度修改，使其远离真实分布。采用 `sequential_multiplicative_additive` 方法，结合乘性和加性噪声。
  - **X异常值**：随机选择一部分样本，将其某个或多个特征值大幅度修改到远离正常分布的区域。
  - **异常值比例**：设置为0%、5%、10%、20%。
  - **异常值强度**：通常设置为5.0，决定异常值偏离正常值的程度。

### 真实数据

实验使用了多个标准的真实世界回归数据集：

- **California Housing (加州住房价格)**：来源 sklearn，20,640个样本，8个数值特征，预测加州各区域的房价中位数。

- **Diabetes (糖尿病)**：来源 sklearn，442个样本，10个数值特征，预测基线后一年疾病进展的量化指标。

- **Boston Housing (波士顿房价)**：经典回归数据集，预测波士顿地区房价中位数。

- **Communities and Crime (社区与犯罪)**：特征较多，预测社区犯罪率，天然适合检验对Y轴异常的鲁棒性。

- **Concrete Compressive Strength (混凝土抗压强度)**：预测混凝土抗压强度，目标值可能因配方等因素出现异常。

- **Bike Sharing (自行车共享)**：较大规模数据集，预测每小时自行车租赁数，目标值可能因特殊事件或天气出现极端波动。

- **Parkinsons Telemonitoring (帕金森病远程监测)**：中等规模，预测帕金森患者运动症状严重程度，生物医学信号特征。

- **异常值注入**：与合成数据相同，仅在训练集和验证集中注入不同比例和强度的异常值，测试集保持纯净。

## 实验流程

1. **数据准备**：
   - 生成合成数据或加载真实数据。
   - 将数据划分为训练集、验证集和测试集。
   - 在训练集和验证集中注入不同比例的异常值。

2. **模型训练**：
   - 在受污染的训练集上训练所有对比模型和CAAR模型。
   - 使用受污染的验证集进行超参数调优。

3. **模型评估**：
   - 在干净的测试集上评估所有模型的性能。
   - 计算各种评估指标：MSE、RMSE、MAE、MdAE、$R^2$。

4. **结果分析**：
   - 创建性能对比表格。
   - 绘制不同异常值比例下的性能趋势图。
   - 绘制残差分析图和预测值与真实值对比图。

5. **实验重复**：
   - 每个实验重复3次，使用不同的随机种子。
   - 计算平均性能和标准差，确保结果的统计可靠性。

## 模型参数设置

### 神经网络模型通用参数
- **隐藏层维度**: `[64, 32]` (合成数据) / `[128, 64]` (真实数据)
- **训练轮数**: 最大100轮
- **学习率**: 0.001
- **批次大小**: 32
- **早停机制**: patience=10, min_delta=0.0001

### 模型特定参数
- **CAAR/GAAR**: `latent_dim=16` (合成数据) / `latent_dim=64` (真实数据)
- **MLP_Huber**: `delta=1.35`
- **MLP_Pinball_Median**: `quantile=0.5`
- **RandomForest**: `n_estimators=100`

## 评估指标

- **均方误差 (Mean Squared Error, MSE)**：评估预测误差的平方平均值。

- **均方根误差 (Root Mean Squared Error, RMSE)**：MSE的平方根，与目标变量单位一致，更直观。

- **平均绝对误差 (Mean Absolute Error, MAE)**：评估预测误差的绝对值平均值，对异常值不那么敏感。

- **中位数绝对误差 (Median Absolute Error, MdAE)**：评估预测误差绝对值的中位数，对异常值更鲁棒。

- **决定系数 (R-squared, $R^2$)**：评估模型解释的因变量变异比例。

## CAAR模型详细介绍

### 统一架构设计

CAAR模型遵循我们提出的统一架构框架，由三个核心组件串联构成：

#### 1. 特征网络 (Feature Network / Representation Network)

- **功能**：从原始输入特征 $x_i$ 中提取高层次、更具表达力的潜在表征 `representation`。

- **实现**：一个独立的多层感知机（MLP）模块，接收原始特征并将其映射到表征空间。

- **输出**：`representation` (维度为 `representation_dim`)。

#### 2. 推断网络 (Abduction Network)

- **功能**：接收特征网络提取的 `representation`，推断出一组通用的潜在参数，包含位置参数和尺度参数。

- **实现**：包含一个共享的MLP，其后是两个并行的输出头：
  - 一个用于生成**位置参数** (`location_param`)
  - 另一个用于生成**尺度参数** (`scale_param`)，经过 `F.softplus` 激活确保为正值

- **输出**：
  - `location_param`: 描述潜在中心趋势的通用参数向量
  - `scale_param`: 描述潜在离散程度的通用参数向量

#### 3. 行动网络 (Action Network)

- **功能**：定义从推断网络产生的 `location_param` 到最终回归结果 $\mu_y$（点估计）的映射规则。

- **实现**：一个简单的线性层模块，执行 $\mu_y = w^T \cdot \text{location\_param} + b$ 的操作。

- **输出**：$\mu_y$ (预测的中心趋势，点估计值)。

### 核心机制

CAAR模型的关键在于如何利用柯西分布的特性来实现鲁棒回归：

- **CAAR的特殊解释**：在CAAR中，推断网络输出的参数被解释为柯西分布的参数：
  - `location_param` 被视为柯西位置参数 $l_i$
  - `scale_param` 被视为柯西尺度参数 $s_i$

- **最终预测分布**：利用柯西分布在线性变换下的特性，对于给定的 $x_i$，模型预测的 $y$ 的条件分布也是一个柯西分布：
  - $p(y | x_i) = \text{Cauchy}(y; \mu_{y_i}, \gamma_{y_i})$
  - 其中：
    - $\mu_{y_i} = w^T \cdot \text{location\_param} + b$ (通过行动网络计算)
    - $\gamma_{y_i} = |w|^T \cdot \text{scale\_param}$ (结合行动网络权重的绝对值)

### 损失函数与训练

使用极大似然估计（MLE）来训练整个模型。损失函数是观测数据 $y_i$ 在模型预测的柯西分布下的负对数似然（NLL）

$$
L = - \sum_{i=1}^n \log \left[ \frac{1}{\pi \gamma_{y_i} \left(1 + \left(\frac{y_i - \mu_{y_i}}{\gamma_{y_i}}\right)^2\right)} \right]
$$

这种设计使得CAAR能够端到端地学习位置和尺度参数，实现对预测结果中心趋势和不确定性的同时建模。

### 优势

- **鲁棒性**：假设并预测柯西分布，天然对 $y$ 中的异常值和重尾数据具有更好的鲁棒性。

- **效率与可扩展性**：推理过程是参数化的，不依赖存储大量训练数据，更适合大规模部署和流式数据场景。

- **高维表示能力**：可以利用高维潜在空间和简单的线性Action Net，实现强大的函数拟合能力。

- **优雅的MLE框架**：巧妙利用柯西分布的代数性质，构建了一个理论上清晰且可通过极大似然直接优化的损失函数。

